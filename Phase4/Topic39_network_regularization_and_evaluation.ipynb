{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization and Evaluation of Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_images\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers import scikit_learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- use `keras` to code up a neural network model;\n",
    "- explain dropout and early stopping as distinctive forms of regularization in neural networks;\n",
    "- use wrappers inside `keras` to make models that can jibe with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "y_binary = y % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported numpy type: NPY_INT).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-75edfcc6d99f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_binary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m--> 263\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported numpy type: NPY_INT)."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y_binary, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to know:\n",
    "\n",
    "- The data and labels in `fit()` need to be numpy arrays, not `pandas` dfs.\n",
    "- Scaling your data will have a large impact on your model.\n",
    "   > For our traditional input features, we would use a scaler object. For images, as long as the minimum value is 0, we can simply divide through by the maximum pixel intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting data ready for modeling\n",
    "**Preprocessing**:\n",
    "\n",
    "- use train_test_split to create X_train, y_train, X_test, and y_test\n",
    "- Split training data into pure_train and validation sets.\n",
    "- Scale the pixel intensity to a value between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling our input variables will help speed up our neural network.\n",
    "\n",
    "Since our minimum intensity is 0, we can normalize the inputs by dividing each value by the max value (16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y_binary, random_state=42, test_size=0.2)\n",
    "\n",
    "X_pure_train, X_val, y_pure_train, y_val =\\\n",
    "    train_test_split(X_train, y_train, random_state=42, test_size=0.2)\n",
    "\n",
    "X_pure_train, X_val, X_test = X_pure_train/16, X_val/16, X_test/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For activation, let's start with the familiar sigmoid function, and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# We will start with our trusty sigmoid function.\n",
    "# What does input dimension correspond to?\n",
    "model.add(Dense(12, activation='sigmoid', input_dim=64))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='SGD' ,\n",
    "              # We use binary_crossentropy for a binary loss function\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Assign the variable history to store the results,\n",
    "# and set verbose=1 so we can see the output. To see\n",
    "# only the metrics at the end of each epoch, set verbose=2.\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=10, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the history of our model via `results.history`.\n",
    "Use __dict__ to take a tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_loss = results.history['loss']\n",
    "sigmoid_accuracy = results.history['accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_loss, ax=ax1, label='loss')\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_accuracy, ax=ax2, label='accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two plots above both relating to the quality of our model.  The left-hand plot is our loss. It uses the probabilities associated with our predictions to judge how well our prediction fits reality. We want it to decrease as far as possible.\n",
    "\n",
    "The accuracy judges how well the predictions are after applying the threshold at the output layer.  We want accuracy to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at our loss, it is still decreasing. That is a signal that our model is **still learning**. If our model is still learning, we can allow it to get better by turning a few dials.\n",
    "\n",
    "Let's:\n",
    "- increase the number of epochs;\n",
    "- change sigmoid activation in the hidden layers to ReLU; and\n",
    "- decrease the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_pure_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4f1b3aa3a78c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_pure_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_pure_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_pure_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_pure_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-be07a86be221>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Assign the variable history to store the results,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# and set verbose=1 so we can see the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pure_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pure_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_pure_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Assign the variable history to store the results,\n",
    "# and set verbose=1 so we can see the output.\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=100, batch_size=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_loss = results.history['loss']\n",
    "sigmoid_accuracy = results.history['accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_loss, ax=ax1, label='loss')\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_accuracy, ax=ax2, label='accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we increase the learning rate to a very high number, we see that our model overshoots the minimum, and starts bouncing all around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "sgd = SGD(lr=9)\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                    epochs=30, batch_size=10, verbose=1)\n",
    "\n",
    "relu_loss = results.history['loss']\n",
    "relu_accuracy = results.history['accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=relu_loss, ax=ax1, label='loss')\n",
    "sns.lineplot(x=results.epoch, y=relu_accuracy, ax=ax2, label='accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "We have been looking only at our training set. Let's add in our validation set to the picture. Check the docstring for the `.fit()` method and add in our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>One answer here</summary>\n",
    "<code>model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                   validation_data=(X_val, y_val),\n",
    "                   epochs=30, batch_size=10)\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting with `sklearn`\n",
    "\n",
    "The `keras.wrappers` submodule means that we can turn `keras` models into estimators that `sklearn` tools will recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001E173A91D00> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-440685741601>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This will throw an error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pure_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pure_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m    398\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    426\u001b[0m                 \u001b[1;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                 \u001b[1;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001E173A91D00> does not."
     ]
    }
   ],
   "source": [
    "# This will throw an error.\n",
    "\n",
    "cross_val_score(model, X_pure_train, y_pure_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu', input_dim=64))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = scikit_learn.KerasClassifier(build_model,\n",
    "                                          epochs=50,\n",
    "                                          batch_size=32,\n",
    "                                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 - 0s - loss: 0.6872 - accuracy: 0.5169\n",
      "Epoch 2/50\n",
      "29/29 - 0s - loss: 0.6745 - accuracy: 0.5582\n",
      "Epoch 3/50\n",
      "29/29 - 0s - loss: 0.6442 - accuracy: 0.6496\n",
      "Epoch 4/50\n",
      "29/29 - 0s - loss: 0.5758 - accuracy: 0.7628\n",
      "Epoch 5/50\n",
      "29/29 - 0s - loss: 0.4844 - accuracy: 0.8694\n",
      "Epoch 6/50\n",
      "29/29 - 0s - loss: 0.4002 - accuracy: 0.8945\n",
      "Epoch 7/50\n",
      "29/29 - 0s - loss: 0.3288 - accuracy: 0.9064\n",
      "Epoch 8/50\n",
      "29/29 - 0s - loss: 0.2800 - accuracy: 0.9119\n",
      "Epoch 9/50\n",
      "29/29 - 0s - loss: 0.2446 - accuracy: 0.9217\n",
      "Epoch 10/50\n",
      "29/29 - 0s - loss: 0.2222 - accuracy: 0.9173\n",
      "Epoch 11/50\n",
      "29/29 - 0s - loss: 0.2087 - accuracy: 0.9227\n",
      "Epoch 12/50\n",
      "29/29 - 0s - loss: 0.1931 - accuracy: 0.9314\n",
      "Epoch 13/50\n",
      "29/29 - 0s - loss: 0.1793 - accuracy: 0.9271\n",
      "Epoch 14/50\n",
      "29/29 - 0s - loss: 0.1712 - accuracy: 0.9380\n",
      "Epoch 15/50\n",
      "29/29 - 0s - loss: 0.1608 - accuracy: 0.9391\n",
      "Epoch 16/50\n",
      "29/29 - 0s - loss: 0.1520 - accuracy: 0.9402\n",
      "Epoch 17/50\n",
      "29/29 - 0s - loss: 0.1454 - accuracy: 0.9423\n",
      "Epoch 18/50\n",
      "29/29 - 0s - loss: 0.1403 - accuracy: 0.9445\n",
      "Epoch 19/50\n",
      "29/29 - 0s - loss: 0.1350 - accuracy: 0.9456\n",
      "Epoch 20/50\n",
      "29/29 - 0s - loss: 0.1318 - accuracy: 0.9467\n",
      "Epoch 21/50\n",
      "29/29 - 0s - loss: 0.1259 - accuracy: 0.9521\n",
      "Epoch 22/50\n",
      "29/29 - 0s - loss: 0.1215 - accuracy: 0.9576\n",
      "Epoch 23/50\n",
      "29/29 - 0s - loss: 0.1185 - accuracy: 0.9576\n",
      "Epoch 24/50\n",
      "29/29 - 0s - loss: 0.1178 - accuracy: 0.9532\n",
      "Epoch 25/50\n",
      "29/29 - 0s - loss: 0.1094 - accuracy: 0.9619\n",
      "Epoch 26/50\n",
      "29/29 - 0s - loss: 0.1055 - accuracy: 0.9663\n",
      "Epoch 27/50\n",
      "29/29 - 0s - loss: 0.1036 - accuracy: 0.9630\n",
      "Epoch 28/50\n",
      "29/29 - 0s - loss: 0.0971 - accuracy: 0.9695\n",
      "Epoch 29/50\n",
      "29/29 - 0s - loss: 0.0949 - accuracy: 0.9695\n",
      "Epoch 30/50\n",
      "29/29 - 0s - loss: 0.0928 - accuracy: 0.9695\n",
      "Epoch 31/50\n",
      "29/29 - 0s - loss: 0.0883 - accuracy: 0.9728\n",
      "Epoch 32/50\n",
      "29/29 - 0s - loss: 0.0878 - accuracy: 0.9684\n",
      "Epoch 33/50\n",
      "29/29 - 0s - loss: 0.0887 - accuracy: 0.9706\n",
      "Epoch 34/50\n",
      "29/29 - 0s - loss: 0.0824 - accuracy: 0.9728\n",
      "Epoch 35/50\n",
      "29/29 - 0s - loss: 0.0776 - accuracy: 0.9771\n",
      "Epoch 36/50\n",
      "29/29 - 0s - loss: 0.0803 - accuracy: 0.9728\n",
      "Epoch 37/50\n",
      "29/29 - 0s - loss: 0.0737 - accuracy: 0.9771\n",
      "Epoch 38/50\n",
      "29/29 - 0s - loss: 0.0715 - accuracy: 0.9782\n",
      "Epoch 39/50\n",
      "29/29 - 0s - loss: 0.0704 - accuracy: 0.9815\n",
      "Epoch 40/50\n",
      "29/29 - 0s - loss: 0.0714 - accuracy: 0.9739\n",
      "Epoch 41/50\n",
      "29/29 - 0s - loss: 0.0718 - accuracy: 0.9750\n",
      "Epoch 42/50\n",
      "29/29 - 0s - loss: 0.0644 - accuracy: 0.9804\n",
      "Epoch 43/50\n",
      "29/29 - 0s - loss: 0.0623 - accuracy: 0.9826\n",
      "Epoch 44/50\n",
      "29/29 - 0s - loss: 0.0606 - accuracy: 0.9815\n",
      "Epoch 45/50\n",
      "29/29 - 0s - loss: 0.0604 - accuracy: 0.9837\n",
      "Epoch 46/50\n",
      "29/29 - 0s - loss: 0.0569 - accuracy: 0.9859\n",
      "Epoch 47/50\n",
      "29/29 - 0s - loss: 0.0548 - accuracy: 0.9837\n",
      "Epoch 48/50\n",
      "29/29 - 0s - loss: 0.0552 - accuracy: 0.9815\n",
      "Epoch 49/50\n",
      "29/29 - 0s - loss: 0.0529 - accuracy: 0.9848\n",
      "Epoch 50/50\n",
      "29/29 - 0s - loss: 0.0511 - accuracy: 0.9859\n",
      "8/8 - 0s - loss: 0.1285 - accuracy: 0.9652\n",
      "Epoch 1/50\n",
      "29/29 - 0s - loss: 0.6847 - accuracy: 0.4951\n",
      "Epoch 2/50\n",
      "29/29 - 0s - loss: 0.6657 - accuracy: 0.5571\n",
      "Epoch 3/50\n",
      "29/29 - 0s - loss: 0.6399 - accuracy: 0.6910\n",
      "Epoch 4/50\n",
      "29/29 - 0s - loss: 0.6033 - accuracy: 0.7845\n",
      "Epoch 5/50\n",
      "29/29 - 0s - loss: 0.5629 - accuracy: 0.8139\n",
      "Epoch 6/50\n",
      "29/29 - 0s - loss: 0.5234 - accuracy: 0.8487\n",
      "Epoch 7/50\n",
      "29/29 - 0s - loss: 0.4921 - accuracy: 0.8694\n",
      "Epoch 8/50\n",
      "29/29 - 0s - loss: 0.4656 - accuracy: 0.8912\n",
      "Epoch 9/50\n",
      "29/29 - 0s - loss: 0.4401 - accuracy: 0.9021\n",
      "Epoch 10/50\n",
      "29/29 - 0s - loss: 0.4207 - accuracy: 0.9151\n",
      "Epoch 11/50\n",
      "29/29 - 0s - loss: 0.4020 - accuracy: 0.9217\n",
      "Epoch 12/50\n",
      "29/29 - 0s - loss: 0.3889 - accuracy: 0.9227\n",
      "Epoch 13/50\n",
      "29/29 - 0s - loss: 0.3758 - accuracy: 0.9249\n",
      "Epoch 14/50\n",
      "29/29 - 0s - loss: 0.3648 - accuracy: 0.9238\n",
      "Epoch 15/50\n",
      "29/29 - 0s - loss: 0.3550 - accuracy: 0.9380\n",
      "Epoch 16/50\n",
      "29/29 - 0s - loss: 0.3422 - accuracy: 0.9325\n",
      "Epoch 17/50\n",
      "29/29 - 0s - loss: 0.3331 - accuracy: 0.9369\n",
      "Epoch 18/50\n",
      "29/29 - 0s - loss: 0.3269 - accuracy: 0.9391\n",
      "Epoch 19/50\n",
      "29/29 - 0s - loss: 0.3186 - accuracy: 0.9391\n",
      "Epoch 20/50\n",
      "29/29 - 0s - loss: 0.3158 - accuracy: 0.9391\n",
      "Epoch 21/50\n",
      "29/29 - 0s - loss: 0.3047 - accuracy: 0.9489\n",
      "Epoch 22/50\n",
      "29/29 - 0s - loss: 0.2935 - accuracy: 0.9434\n",
      "Epoch 23/50\n",
      "29/29 - 0s - loss: 0.2859 - accuracy: 0.9543\n",
      "Epoch 24/50\n",
      "29/29 - 0s - loss: 0.2789 - accuracy: 0.9597\n",
      "Epoch 25/50\n",
      "29/29 - 0s - loss: 0.2725 - accuracy: 0.9630\n",
      "Epoch 26/50\n",
      "29/29 - 0s - loss: 0.2657 - accuracy: 0.9630\n",
      "Epoch 27/50\n",
      "29/29 - 0s - loss: 0.2590 - accuracy: 0.9652\n",
      "Epoch 28/50\n",
      "29/29 - 0s - loss: 0.2541 - accuracy: 0.9641\n",
      "Epoch 29/50\n",
      "29/29 - 0s - loss: 0.2473 - accuracy: 0.9684\n",
      "Epoch 30/50\n",
      "29/29 - 0s - loss: 0.2433 - accuracy: 0.9706\n",
      "Epoch 31/50\n",
      "29/29 - 0s - loss: 0.2376 - accuracy: 0.9695\n",
      "Epoch 32/50\n",
      "29/29 - 0s - loss: 0.2314 - accuracy: 0.9728\n",
      "Epoch 33/50\n",
      "29/29 - 0s - loss: 0.2265 - accuracy: 0.9739\n",
      "Epoch 34/50\n",
      "29/29 - 0s - loss: 0.2231 - accuracy: 0.9739\n",
      "Epoch 35/50\n",
      "29/29 - 0s - loss: 0.2182 - accuracy: 0.9750\n",
      "Epoch 36/50\n",
      "29/29 - 0s - loss: 0.2136 - accuracy: 0.9728\n",
      "Epoch 37/50\n",
      "29/29 - 0s - loss: 0.2096 - accuracy: 0.9761\n",
      "Epoch 38/50\n",
      "29/29 - 0s - loss: 0.2068 - accuracy: 0.9739\n",
      "Epoch 39/50\n",
      "29/29 - 0s - loss: 0.2014 - accuracy: 0.9782\n",
      "Epoch 40/50\n",
      "29/29 - 0s - loss: 0.1995 - accuracy: 0.9771\n",
      "Epoch 41/50\n",
      "29/29 - 0s - loss: 0.1943 - accuracy: 0.9793\n",
      "Epoch 42/50\n",
      "29/29 - 0s - loss: 0.1892 - accuracy: 0.9793\n",
      "Epoch 43/50\n",
      "29/29 - 0s - loss: 0.1857 - accuracy: 0.9782\n",
      "Epoch 44/50\n",
      "29/29 - 0s - loss: 0.1821 - accuracy: 0.9804\n",
      "Epoch 45/50\n",
      "29/29 - 0s - loss: 0.1791 - accuracy: 0.9815\n",
      "Epoch 46/50\n",
      "29/29 - 0s - loss: 0.1776 - accuracy: 0.9804\n",
      "Epoch 47/50\n",
      "29/29 - 0s - loss: 0.1740 - accuracy: 0.9782\n",
      "Epoch 48/50\n",
      "29/29 - 0s - loss: 0.1698 - accuracy: 0.9826\n",
      "Epoch 49/50\n",
      "29/29 - 0s - loss: 0.1676 - accuracy: 0.9804\n",
      "Epoch 50/50\n",
      "29/29 - 0s - loss: 0.1654 - accuracy: 0.9815\n",
      "8/8 - 0s - loss: 0.1957 - accuracy: 0.9478\n",
      "Epoch 1/50\n",
      "29/29 - 0s - loss: 0.6914 - accuracy: 0.5365\n",
      "Epoch 2/50\n",
      "29/29 - 0s - loss: 0.6599 - accuracy: 0.6812\n",
      "Epoch 3/50\n",
      "29/29 - 0s - loss: 0.6112 - accuracy: 0.7617\n",
      "Epoch 4/50\n",
      "29/29 - 0s - loss: 0.5482 - accuracy: 0.7965\n",
      "Epoch 5/50\n",
      "29/29 - 0s - loss: 0.4744 - accuracy: 0.8183\n",
      "Epoch 6/50\n",
      "29/29 - 0s - loss: 0.4058 - accuracy: 0.8422\n",
      "Epoch 7/50\n",
      "29/29 - 0s - loss: 0.3516 - accuracy: 0.8640\n",
      "Epoch 8/50\n",
      "29/29 - 0s - loss: 0.3109 - accuracy: 0.8716\n",
      "Epoch 9/50\n",
      "29/29 - 0s - loss: 0.2846 - accuracy: 0.8781\n",
      "Epoch 10/50\n",
      "29/29 - 0s - loss: 0.2596 - accuracy: 0.8945\n",
      "Epoch 11/50\n",
      "29/29 - 0s - loss: 0.2452 - accuracy: 0.8955\n",
      "Epoch 12/50\n",
      "29/29 - 0s - loss: 0.2319 - accuracy: 0.8977\n",
      "Epoch 13/50\n",
      "29/29 - 0s - loss: 0.2245 - accuracy: 0.9021\n",
      "Epoch 14/50\n",
      "29/29 - 0s - loss: 0.2174 - accuracy: 0.9053\n",
      "Epoch 15/50\n",
      "29/29 - 0s - loss: 0.2086 - accuracy: 0.9042\n",
      "Epoch 16/50\n",
      "29/29 - 0s - loss: 0.2012 - accuracy: 0.9108\n",
      "Epoch 17/50\n",
      "29/29 - 0s - loss: 0.1956 - accuracy: 0.9108\n",
      "Epoch 18/50\n",
      "29/29 - 0s - loss: 0.1926 - accuracy: 0.9140\n",
      "Epoch 19/50\n",
      "29/29 - 0s - loss: 0.1858 - accuracy: 0.9173\n",
      "Epoch 20/50\n",
      "29/29 - 0s - loss: 0.1810 - accuracy: 0.9195\n",
      "Epoch 21/50\n",
      "29/29 - 0s - loss: 0.1793 - accuracy: 0.9227\n",
      "Epoch 22/50\n",
      "29/29 - 0s - loss: 0.1747 - accuracy: 0.9293\n",
      "Epoch 23/50\n",
      "29/29 - 0s - loss: 0.1711 - accuracy: 0.9314\n",
      "Epoch 24/50\n",
      "29/29 - 0s - loss: 0.1708 - accuracy: 0.9282\n",
      "Epoch 25/50\n",
      "29/29 - 0s - loss: 0.1658 - accuracy: 0.9336\n",
      "Epoch 26/50\n",
      "29/29 - 0s - loss: 0.1606 - accuracy: 0.9358\n",
      "Epoch 27/50\n",
      "29/29 - 0s - loss: 0.1704 - accuracy: 0.9304\n",
      "Epoch 28/50\n",
      "29/29 - 0s - loss: 0.1607 - accuracy: 0.9380\n",
      "Epoch 29/50\n",
      "29/29 - 0s - loss: 0.1585 - accuracy: 0.9325\n",
      "Epoch 30/50\n",
      "29/29 - 0s - loss: 0.1530 - accuracy: 0.9402\n",
      "Epoch 31/50\n",
      "29/29 - 0s - loss: 0.1502 - accuracy: 0.9434\n",
      "Epoch 32/50\n",
      "29/29 - 0s - loss: 0.1503 - accuracy: 0.9412\n",
      "Epoch 33/50\n",
      "29/29 - 0s - loss: 0.1540 - accuracy: 0.9358\n",
      "Epoch 34/50\n",
      "29/29 - 0s - loss: 0.1505 - accuracy: 0.9402\n",
      "Epoch 35/50\n",
      "29/29 - 0s - loss: 0.1435 - accuracy: 0.9456\n",
      "Epoch 36/50\n",
      "29/29 - 0s - loss: 0.1469 - accuracy: 0.9369\n",
      "Epoch 37/50\n",
      "29/29 - 0s - loss: 0.1436 - accuracy: 0.9467\n",
      "Epoch 38/50\n",
      "29/29 - 0s - loss: 0.1406 - accuracy: 0.9445\n",
      "Epoch 39/50\n",
      "29/29 - 0s - loss: 0.1404 - accuracy: 0.9478\n",
      "Epoch 40/50\n",
      "29/29 - 0s - loss: 0.1389 - accuracy: 0.9478\n",
      "Epoch 41/50\n",
      "29/29 - 0s - loss: 0.1348 - accuracy: 0.9456\n",
      "Epoch 42/50\n",
      "29/29 - 0s - loss: 0.1343 - accuracy: 0.9499\n",
      "Epoch 43/50\n",
      "29/29 - 0s - loss: 0.1338 - accuracy: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "29/29 - 0s - loss: 0.1332 - accuracy: 0.9478\n",
      "Epoch 45/50\n",
      "29/29 - 0s - loss: 0.1280 - accuracy: 0.9510\n",
      "Epoch 46/50\n",
      "29/29 - 0s - loss: 0.1296 - accuracy: 0.9489\n",
      "Epoch 47/50\n",
      "29/29 - 0s - loss: 0.1259 - accuracy: 0.9543\n",
      "Epoch 48/50\n",
      "29/29 - 0s - loss: 0.1306 - accuracy: 0.9467\n",
      "Epoch 49/50\n",
      "29/29 - 0s - loss: 0.1275 - accuracy: 0.9510\n",
      "Epoch 50/50\n",
      "29/29 - 0s - loss: 0.1249 - accuracy: 0.9499\n",
      "8/8 - 0s - loss: 0.1719 - accuracy: 0.9174\n",
      "Epoch 1/50\n",
      "29/29 - 0s - loss: 0.6820 - accuracy: 0.6257\n",
      "Epoch 2/50\n",
      "29/29 - 0s - loss: 0.6385 - accuracy: 0.8139\n",
      "Epoch 3/50\n",
      "29/29 - 0s - loss: 0.5756 - accuracy: 0.8411\n",
      "Epoch 4/50\n",
      "29/29 - 0s - loss: 0.4973 - accuracy: 0.8564\n",
      "Epoch 5/50\n",
      "29/29 - 0s - loss: 0.4141 - accuracy: 0.8749\n",
      "Epoch 6/50\n",
      "29/29 - 0s - loss: 0.3480 - accuracy: 0.8727\n",
      "Epoch 7/50\n",
      "29/29 - 0s - loss: 0.3021 - accuracy: 0.8890\n",
      "Epoch 8/50\n",
      "29/29 - 0s - loss: 0.2684 - accuracy: 0.8945\n",
      "Epoch 9/50\n",
      "29/29 - 0s - loss: 0.2452 - accuracy: 0.9042\n",
      "Epoch 10/50\n",
      "29/29 - 0s - loss: 0.2274 - accuracy: 0.9119\n",
      "Epoch 11/50\n",
      "29/29 - 0s - loss: 0.2116 - accuracy: 0.9195\n",
      "Epoch 12/50\n",
      "29/29 - 0s - loss: 0.1978 - accuracy: 0.9238\n",
      "Epoch 13/50\n",
      "29/29 - 0s - loss: 0.1843 - accuracy: 0.9293\n",
      "Epoch 14/50\n",
      "29/29 - 0s - loss: 0.1773 - accuracy: 0.9304\n",
      "Epoch 15/50\n",
      "29/29 - 0s - loss: 0.1649 - accuracy: 0.9358\n",
      "Epoch 16/50\n",
      "29/29 - 0s - loss: 0.1553 - accuracy: 0.9456\n",
      "Epoch 17/50\n",
      "29/29 - 0s - loss: 0.1521 - accuracy: 0.9478\n",
      "Epoch 18/50\n",
      "29/29 - 0s - loss: 0.1415 - accuracy: 0.9467\n",
      "Epoch 19/50\n",
      "29/29 - 0s - loss: 0.1335 - accuracy: 0.9478\n",
      "Epoch 20/50\n",
      "29/29 - 0s - loss: 0.1268 - accuracy: 0.9467\n",
      "Epoch 21/50\n",
      "29/29 - 0s - loss: 0.1203 - accuracy: 0.9576\n",
      "Epoch 22/50\n",
      "29/29 - 0s - loss: 0.1145 - accuracy: 0.9619\n",
      "Epoch 23/50\n",
      "29/29 - 0s - loss: 0.1069 - accuracy: 0.9630\n",
      "Epoch 24/50\n",
      "29/29 - 0s - loss: 0.1017 - accuracy: 0.9641\n",
      "Epoch 25/50\n",
      "29/29 - 0s - loss: 0.0957 - accuracy: 0.9663\n",
      "Epoch 26/50\n",
      "29/29 - 0s - loss: 0.0947 - accuracy: 0.9695\n",
      "Epoch 27/50\n",
      "29/29 - 0s - loss: 0.0887 - accuracy: 0.9663\n",
      "Epoch 28/50\n",
      "29/29 - 0s - loss: 0.0807 - accuracy: 0.9750\n",
      "Epoch 29/50\n",
      "29/29 - 0s - loss: 0.0786 - accuracy: 0.9728\n",
      "Epoch 30/50\n",
      "29/29 - 0s - loss: 0.0752 - accuracy: 0.9728\n",
      "Epoch 31/50\n",
      "29/29 - 0s - loss: 0.0693 - accuracy: 0.9793\n",
      "Epoch 32/50\n",
      "29/29 - 0s - loss: 0.0663 - accuracy: 0.9782\n",
      "Epoch 33/50\n",
      "29/29 - 0s - loss: 0.0680 - accuracy: 0.9739\n",
      "Epoch 34/50\n",
      "29/29 - 0s - loss: 0.0750 - accuracy: 0.9706\n",
      "Epoch 35/50\n",
      "29/29 - 0s - loss: 0.0626 - accuracy: 0.9771\n",
      "Epoch 36/50\n",
      "29/29 - 0s - loss: 0.0549 - accuracy: 0.9793\n",
      "Epoch 37/50\n",
      "29/29 - 0s - loss: 0.0545 - accuracy: 0.9804\n",
      "Epoch 38/50\n",
      "29/29 - 0s - loss: 0.0525 - accuracy: 0.9804\n",
      "Epoch 39/50\n",
      "29/29 - 0s - loss: 0.0493 - accuracy: 0.9848\n",
      "Epoch 40/50\n",
      "29/29 - 0s - loss: 0.0485 - accuracy: 0.9837\n",
      "Epoch 41/50\n",
      "29/29 - 0s - loss: 0.0454 - accuracy: 0.9815\n",
      "Epoch 42/50\n",
      "29/29 - 0s - loss: 0.0466 - accuracy: 0.9826\n",
      "Epoch 43/50\n",
      "29/29 - 0s - loss: 0.0423 - accuracy: 0.9869\n",
      "Epoch 44/50\n",
      "29/29 - 0s - loss: 0.0372 - accuracy: 0.9935\n",
      "Epoch 45/50\n",
      "29/29 - 0s - loss: 0.0358 - accuracy: 0.9924\n",
      "Epoch 46/50\n",
      "29/29 - 0s - loss: 0.0332 - accuracy: 0.9946\n",
      "Epoch 47/50\n",
      "29/29 - 0s - loss: 0.0323 - accuracy: 0.9946\n",
      "Epoch 48/50\n",
      "29/29 - 0s - loss: 0.0313 - accuracy: 0.9924\n",
      "Epoch 49/50\n",
      "29/29 - 0s - loss: 0.0299 - accuracy: 0.9946\n",
      "Epoch 50/50\n",
      "29/29 - 0s - loss: 0.0282 - accuracy: 0.9946\n",
      "8/8 - 0s - loss: 0.0967 - accuracy: 0.9609\n",
      "Epoch 1/50\n",
      "29/29 - 0s - loss: 0.6826 - accuracy: 0.6272\n",
      "Epoch 2/50\n",
      "29/29 - 0s - loss: 0.6560 - accuracy: 0.7022\n",
      "Epoch 3/50\n",
      "29/29 - 0s - loss: 0.6161 - accuracy: 0.7946\n",
      "Epoch 4/50\n",
      "29/29 - 0s - loss: 0.5368 - accuracy: 0.8413\n",
      "Epoch 5/50\n",
      "29/29 - 0s - loss: 0.4224 - accuracy: 0.8750\n",
      "Epoch 6/50\n",
      "29/29 - 0s - loss: 0.3252 - accuracy: 0.8891\n",
      "Epoch 7/50\n",
      "29/29 - 0s - loss: 0.2667 - accuracy: 0.9054\n",
      "Epoch 8/50\n",
      "29/29 - 0s - loss: 0.2328 - accuracy: 0.9109\n",
      "Epoch 9/50\n",
      "29/29 - 0s - loss: 0.2180 - accuracy: 0.9087\n",
      "Epoch 10/50\n",
      "29/29 - 0s - loss: 0.2024 - accuracy: 0.9196\n",
      "Epoch 11/50\n",
      "29/29 - 0s - loss: 0.1863 - accuracy: 0.9293\n",
      "Epoch 12/50\n",
      "29/29 - 0s - loss: 0.1754 - accuracy: 0.9272\n",
      "Epoch 13/50\n",
      "29/29 - 0s - loss: 0.1683 - accuracy: 0.9326\n",
      "Epoch 14/50\n",
      "29/29 - 0s - loss: 0.1614 - accuracy: 0.9348\n",
      "Epoch 15/50\n",
      "29/29 - 0s - loss: 0.1509 - accuracy: 0.9435\n",
      "Epoch 16/50\n",
      "29/29 - 0s - loss: 0.1420 - accuracy: 0.9457\n",
      "Epoch 17/50\n",
      "29/29 - 0s - loss: 0.1370 - accuracy: 0.9511\n",
      "Epoch 18/50\n",
      "29/29 - 0s - loss: 0.1322 - accuracy: 0.9511\n",
      "Epoch 19/50\n",
      "29/29 - 0s - loss: 0.1277 - accuracy: 0.9565\n",
      "Epoch 20/50\n",
      "29/29 - 0s - loss: 0.1212 - accuracy: 0.9511\n",
      "Epoch 21/50\n",
      "29/29 - 0s - loss: 0.1156 - accuracy: 0.9598\n",
      "Epoch 22/50\n",
      "29/29 - 0s - loss: 0.1091 - accuracy: 0.9630\n",
      "Epoch 23/50\n",
      "29/29 - 0s - loss: 0.1080 - accuracy: 0.9641\n",
      "Epoch 24/50\n",
      "29/29 - 0s - loss: 0.1057 - accuracy: 0.9663\n",
      "Epoch 25/50\n",
      "29/29 - 0s - loss: 0.1111 - accuracy: 0.9630\n",
      "Epoch 26/50\n",
      "29/29 - 0s - loss: 0.0960 - accuracy: 0.9652\n",
      "Epoch 27/50\n",
      "29/29 - 0s - loss: 0.0902 - accuracy: 0.9674\n",
      "Epoch 28/50\n",
      "29/29 - 0s - loss: 0.0900 - accuracy: 0.9717\n",
      "Epoch 29/50\n",
      "29/29 - 0s - loss: 0.0851 - accuracy: 0.9707\n",
      "Epoch 30/50\n",
      "29/29 - 0s - loss: 0.0824 - accuracy: 0.9739\n",
      "Epoch 31/50\n",
      "29/29 - 0s - loss: 0.0812 - accuracy: 0.9761\n",
      "Epoch 32/50\n",
      "29/29 - 0s - loss: 0.0771 - accuracy: 0.9728\n",
      "Epoch 33/50\n",
      "29/29 - 0s - loss: 0.0766 - accuracy: 0.9750\n",
      "Epoch 34/50\n",
      "29/29 - 0s - loss: 0.0723 - accuracy: 0.9783\n",
      "Epoch 35/50\n",
      "29/29 - 0s - loss: 0.0708 - accuracy: 0.9750\n",
      "Epoch 36/50\n",
      "29/29 - 0s - loss: 0.0688 - accuracy: 0.9793\n",
      "Epoch 37/50\n",
      "29/29 - 0s - loss: 0.0707 - accuracy: 0.9750\n",
      "Epoch 38/50\n",
      "29/29 - 0s - loss: 0.0642 - accuracy: 0.9815\n",
      "Epoch 39/50\n",
      "29/29 - 0s - loss: 0.0635 - accuracy: 0.9804\n",
      "Epoch 40/50\n",
      "29/29 - 0s - loss: 0.0643 - accuracy: 0.9815\n",
      "Epoch 41/50\n",
      "29/29 - 0s - loss: 0.0595 - accuracy: 0.9826\n",
      "Epoch 42/50\n",
      "29/29 - 0s - loss: 0.0574 - accuracy: 0.9815\n",
      "Epoch 43/50\n",
      "29/29 - 0s - loss: 0.0552 - accuracy: 0.9848\n",
      "Epoch 44/50\n",
      "29/29 - 0s - loss: 0.0555 - accuracy: 0.9848\n",
      "Epoch 45/50\n",
      "29/29 - 0s - loss: 0.0600 - accuracy: 0.9837\n",
      "Epoch 46/50\n",
      "29/29 - 0s - loss: 0.0526 - accuracy: 0.9837\n",
      "Epoch 47/50\n",
      "29/29 - 0s - loss: 0.0505 - accuracy: 0.9848\n",
      "Epoch 48/50\n",
      "29/29 - 0s - loss: 0.0489 - accuracy: 0.9848\n",
      "Epoch 49/50\n",
      "29/29 - 0s - loss: 0.0480 - accuracy: 0.9859\n",
      "Epoch 50/50\n",
      "29/29 - 0s - loss: 0.0452 - accuracy: 0.9870\n",
      "8/8 - 0s - loss: 0.1366 - accuracy: 0.9301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96521741, 0.94782609, 0.9173913 , 0.96086955, 0.93013102])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(keras_model, X_pure_train, y_pure_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does regularization make sense in the context of neural networks? <br/>\n",
    "\n",
    "Yes! We still have all of the salient ingredients: a loss function, overfitting vs. underfitting, and coefficients (weights) that could get too large.\n",
    "\n",
    "But there are now a few different flavors besides L1 and L2 regularization. (Note that L1 regularization is not common in the context of  neural networks.)\n",
    "\n",
    "We'll add a few more layers to give regularization a better chance of making a difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported numpy type: NPY_INT).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2cc369e4ff0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m results = model.fit(X_pure_train, y_pure_train, epochs=20, batch_size=32,\n\u001b[0m\u001b[0;32m     25\u001b[0m                     verbose=0, validation_data=(X_val, y_val))\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m--> 263\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported numpy type: NPY_INT)."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "\n",
    "# We can add L2 (or L1) regularization right into\n",
    "# the layer with the kernel_regularizer parameter.\n",
    "\n",
    "model.add(Dense(20, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.05)))\n",
    "\n",
    "# Note that there is also a bias_regularizer,\n",
    "# but this tends to have less effect.\n",
    "\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=20, batch_size=32,\n",
    "                    verbose=0, validation_data=(X_val, y_val))\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding L2 to multiple layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu',\n",
    "                input_dim=64))\n",
    "model.add(Dense(20, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "\n",
    "model.add(Dense(12, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(12, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(12, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(8, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(4, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=20, batch_size=32,\n",
    "                    verbose=0, validation_data=(X_val, y_val))\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "We can also specify a dropout layer in keras, which randomly shuts off different nodes during training. This can help to prevent overfitting.\n",
    "\n",
    "![drop_out](images/drop_out.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "To add dropout to a `keras` network, simply add it as though it were a layer. It will apply to the immediately preceding layer.\n",
    "\n",
    "Add Dropout to one or more layers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=50,\n",
    "                    batch_size= 32, verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>One answer here</summary>\n",
    "<code>model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=50,\n",
    "                    batch_size= 32, verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also tell our neural network to stop once it stops realizing any gain.\n",
    "\n",
    "Here we tell it to stop once the a very small positive change in the validation loss occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the EarlyStopping object\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-8,\n",
    "                           verbose=1,\n",
    "                           mode='min')\n",
    "\n",
    "# Place this in a list as the value of the `callbacks` parameter\n",
    "# in the `.fit()` method.\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                    epochs=20, batch_size=32,\n",
    "                    verbose=0, validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "That probably stopped too early. We can specify the number of epochs in which it doesn't see decrease in the loss with the `patience` parameter. Modify the code below to include an Early Stop with a patience of 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the EarlyStopping object\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-8,\n",
    "                           verbose=1, patience=5,\n",
    "                           mode='min')\n",
    "\n",
    "# Place this in a list as the value of the `callbacks` parameter\n",
    "# in the `.fit()` method.\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                    epochs=50, batch_size= 32,\n",
    "                    verbose=0, validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>One answer here</summary>\n",
    "<code>model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the EarlyStopping object\n",
    "\n",
    "\n",
    "\n",
    "# Place this in a list as the value of the `callbacks` parameter\n",
    "# in the `.fit()` method.\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                    epochs=50, batch_size= 32,\n",
    "                    verbose=0, validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification and Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's return to the problem of predicting digits 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.2)\n",
    "X_pure_train, X_val, y_pure_train, y_val =\\\n",
    "    train_test_split(X_train, y_train,\n",
    "                     random_state=42, test_size=0.2)\n",
    "X_pure_train, X_val, X_test = X_pure_train/16, X_val/16, X_test/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a multiclass output, our neural net expects our target to be in a certain form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "y_pure_train = ohe.fit_transform(y_pure_train.reshape(-1,1))\n",
    "y_val = ohe.transform(y_val.reshape(-1,1))\n",
    "y_test = ohe.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from above, but now with ten output neurons:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                   epochs=50, batch_size=10,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$\n",
    "\n",
    "The sofmax function outputs a number between 0 and 1 for each of our classes.  All of the probabilities of the classes sum up to 1.\n",
    "\n",
    "The number of nodes in our output layer equals the number of categories in our dataset.\n",
    "\n",
    "We also need a new loss function: **categorical crossentropy**, which calculates a separate loss for each label and then sums the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = results.history\n",
    "training_loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "training_accuracy = history['accuracy']\n",
    "val_accuracy = history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "\n",
    "sns.lineplot(x=list(range(len(training_loss))),\n",
    "             y=training_loss, color='r', label='training', ax=ax1)\n",
    "sns.lineplot(x=list(range(len(val_loss))),\n",
    "             y=val_loss, color='b', label='validation', ax=ax1)\n",
    "sns.lineplot(x=list(range(len(training_loss))),\n",
    "             y=training_accuracy, color='r', label='training',ax=ax2)\n",
    "sns.lineplot(x=list(range(len(val_loss))),\n",
    "             y=val_accuracy, color='b', label='validation',ax=ax2)\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_restore = ohe.inverse_transform(y_test)\n",
    "confusion_matrix(y_test_restore, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, look at that performance!  \n",
    "\n",
    "That is great, but remember, we were dealing with simple black and white images.  With color, our basic neural net will have less success.\n",
    "\n",
    "We will explore more advanced tools in the coming days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "EdZDyJfARV8l"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "intro-to-keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
